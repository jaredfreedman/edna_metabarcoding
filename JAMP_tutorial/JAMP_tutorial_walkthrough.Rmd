---
title: "JAMP Tutorial Walkthrough"
output: html_notebook
editor_options: 
  chunk_output_type: console
---

# R Markdown

## Set Working Directory

```{r include=FALSE}
# set working directory to proper repo

setwd("/Users/jaredfreedman/Research/git/edna_metabarcoding/JAMP_tutorial")
# download the raw data from and place it into the tutorial folder (Study we are looking at https://peerj.com/articles/3006/) 
# MiSeq Run1, R1 direction:
# https://dx.doi.org/10.6084/m9.figshare.4039821.v1
# MiSeq Run1, R2 direction:
# https://dx.doi.org/10.6084/m9.figshare.4039860.v1
```

## Download tutorial fastq files and set up folders (if not starting from beginning)

```{r include=FALSE}
#load JAMP
#library("JAMP")

# Download tutorial fastq files to wd -------------------------------------

download.file("https://ndownloader.figshare.com/files/6503952", "16_S10_L001_R1_001_run1.fastq.gz")
download.file("https://ndownloader.figshare.com/files/6503991", "16_S10_L001_R2_001_run1.fastq.gz")
system2("gunzip", "16_S10_L001_R1_001_run1.fastq.gz")
system2("gunzip", "16_S10_L001_R2_001_run1.fastq.gz")


list.files()

# JAMP generates a new folder for each processing step! Should your files alreay be demultiplexed or you want to start somwhere else in the pipeline with preprocessed reads, you can generate an empty folder and place your files to be processed in "_data"
#Empty_folder()

#To delete the last generated folder, run
#Remove_last_folder()
```

## Demultiplex samples

```{r echo=FALSE}
# In this example we are dealing with sequence raw data that is not yet demultiplexed. To demultiplex run:


Demultiplexing_shifted(file1="16_S10_L001_R1_001_run1.fastq",
                       file2="16_S10_L001_R2_001_run1.fastq",
                       tags="../../JAMP/Tutorial/_converter/indexe_1.csv",
                       combinations="../../JAMP/Tutorial/_converter/combos_1.csv")


#file1 and file2 are the sequencing files, indexe_1.csv is the index file, and combos_1.csv is the combination of shifts in primers
```

## Check for PhiX

```{r}
# check for PhiX

# only subsample 10000 reads

if(T){
  system2("vsearch", 
          "-fastx_subsample A_Demultiplexing_shifted/_data/N_debris_R1.fastq -fastaout A_Demultiplexing_shifted/_data/N_debris_R1.fasta -sample_size 10000")
} else { # check all reads in read 1 for PhiX
  system2("paste",
          " - - - - < A_Demultiplexing_shifted/_data/N_debris_R1.fastq | cut -f 1,2 | sed 's/^@/>/' | tr \"\t\" \"\n\" > A_Demultiplexing_shifted/_data/N_debris_R1.fasta")
}


system2("vsearch",
        "-usearch_global A_Demultiplexing_shifted/_data/N_debris_R1.fasta -db ../../JAMP/Tutorial/PhiX.fasta -id 0.9 -strand both -blast6out PhiX_table.txt -maxrejects 1 -maxaccepts 1")
```


## Merge pair-ended reads

```{r include=FALSE}

Merge_PE()

```


## Trim primers 
for this tutorial, it trims the mlCOIintF and jgHCO primers
```{r inlcude=FALSE}

# trim primers (mlCOIintF and jgHCO)

Cutadapt(forward="GGWACWGGWTGAACWGTWTAYCCYCC",
         reverse="TAIACYTCIGGRTGICCRAARAAYCA",
         bothsides=T)

#by using "bothsides=T", forward or reverse primers are detected on both ends. This is not nessesary for fusion primers.

```


## Discard non-target length (within 20bp) and discard reads above 1 expected error
```{r include=FALSE}

# discard with non target length
Minmax(min=(313-10), max=(313+10))

# discard reads above 1 expected error
Max_ee(max_ee=1)

Max_ee()

```

## Subsample to 60000, then cluster into OTUs
This will not work! It only works in USearch, not VSearch :( I included this as reference, with code hashtagged out
```{r include = FALSE}

# subsample to lowest sample size, should be done if samples are widely different in sequencing depth (as one starts with)
# needs to be updated, right now still on usearch! Vserch not supported right now

#U_subset(sample_size=60000)

#cluster OTUs

#Cluster_otus(filter=0.01)
#file.rename("G_U_cluster_otus", "G_U_cluster_otus - 60k")

```

## Cluster OTUs without subsetting
This takes direclty from Max_ee output

```{r include=FALSE}

#cluster OTUs (without subsetting)
no_subset <- list.files("K_U_max_ee/_data", full.names=T)

U_cluster_otus(files= no_subset, filter=0.01)

```



